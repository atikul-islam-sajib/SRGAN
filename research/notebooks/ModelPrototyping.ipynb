{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import zipfile\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_PATH = \"../../data/raw/\"\n",
    "PROCESSED_DATA_PATH = \"../../data/processed/\"\n",
    "FILES_PATH = \"../../research/files/\"\n",
    "TRAIN_MODELS = \"../../checkpoints/train_models/\"\n",
    "BEST_MODELS = \"../../checkpoints/best_models/\"\n",
    "BEST_MODEL = \"../../checkpoints/best_model/\"\n",
    "TRAIN_IMAGES = \"../../outputs/train_images/\"\n",
    "TEST_IMAGES = \"../../outputs/test_images/\"\n",
    "GIF_FILE = \"../../outputs/train_gif\"\n",
    "METRICS_PATH = \"../../metrics/\"\n",
    "MODEL_HISTORY = \"../../checkpoints/model_history/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utils file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump(value, filename):\n",
    "    if (value is not None) and (filename is not None):\n",
    "        joblib.dump(value=value, filename=filename)\n",
    "    else:\n",
    "        raise Exception(\"Value or filename not provided\")\n",
    "    \n",
    "def load(filename):\n",
    "    if (filename is not None):\n",
    "        return joblib.load(filename=filename)\n",
    "    else:\n",
    "        raise Exception(\"Filename not provided\")\n",
    "    \n",
    "def weight_init(m, he_normal = False):\n",
    "    classname = m.__class__.__name__\n",
    "    \n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        if he_normal:\n",
    "            nn.init.kaiming_normal_(\n",
    "                m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "        else:\n",
    "            nn.init.normal_(m.weight, mean=0.0, std=0.02)\n",
    "            \n",
    "    elif classname.find(\"BatchNorm\")!= -1:\n",
    "        if he_normal:\n",
    "            nn.init.kaiming_normal_(\n",
    "                m.weight, mode=\"fan_out\", nonlinearity=\"relu\")        \n",
    "        else:\n",
    "            nn.init.normal_(m.weight, mean=1.0, std=0.02)\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "            \n",
    "            \n",
    "def device_init(device = \"mps\"):\n",
    "    if device == \"mps\":\n",
    "        return torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    elif device == \"cuda\":\n",
    "        return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader(Dataset):\n",
    "    def __init__(self, image_path = None, in_channels = 3, batch_size = 1, image_size = 64):\n",
    "        self.image_path = image_path\n",
    "        self.batch_size = batch_size\n",
    "        self.in_channels = in_channels\n",
    "        self.image_size = image_size\n",
    "\n",
    "        self.train_images = list()\n",
    "        self.train_labels = list()\n",
    "        self.test_images = list()\n",
    "        self.test_labels = list()\n",
    "\n",
    "    def image_normalized(self, lr_images=True):\n",
    "        return transforms.Compose(\n",
    "            [\n",
    "                (\n",
    "                    transforms.Resize((self.image_size, self.image_size))\n",
    "                    if lr_images\n",
    "                    else transforms.Resize((self.image_size*4, self.image_size*4))\n",
    "                ),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def unzip_folder(self):\n",
    "        if os.path.exists(RAW_DATA_PATH):\n",
    "            with zipfile.ZipFile(self.image_path, \"r\") as zip_file:\n",
    "                zip_file.extractall(os.path.join(RAW_DATA_PATH, \"images\"))\n",
    "        else:\n",
    "            raise Exception(\"Raw data folder not found\".capitalize())\n",
    "\n",
    "    def extract_images(self):\n",
    "        if os.path.exists(RAW_DATA_PATH):\n",
    "            image_path = os.path.join(RAW_DATA_PATH, \"images\")\n",
    "\n",
    "            train_images = os.path.join(image_path, os.listdir(image_path)[0])\n",
    "            test_images = os.path.join(image_path, os.listdir(image_path)[1])\n",
    "\n",
    "            for idx, path in enumerate([train_images, test_images]):\n",
    "                categories = os.listdir(path)\n",
    "\n",
    "                for category in categories:\n",
    "                    images = os.path.join(path, category)\n",
    "\n",
    "                    for image in os.listdir(images):\n",
    "                        self.image_path = os.path.join(images, image)\n",
    "                        self.image = cv2.imread(self.image_path)\n",
    "\n",
    "                        if self.image is not None:\n",
    "                            if idx == 0:\n",
    "                                self.train_images.append(\n",
    "                                    self.image_normalized(lr_images=True)(\n",
    "                                        Image.fromarray(self.image)\n",
    "                                    )\n",
    "                                )\n",
    "\n",
    "                                self.train_labels.append(\n",
    "                                    self.image_normalized(lr_images=False)(\n",
    "                                        Image.fromarray(self.image)\n",
    "                                    )\n",
    "                                )\n",
    "                            else:\n",
    "                                self.test_images.append(\n",
    "                                    self.image_normalized(lr_images=True)(\n",
    "                                        Image.fromarray(self.image)\n",
    "                                    )\n",
    "                                )\n",
    "\n",
    "                                self.test_labels.append(\n",
    "                                    self.image_normalized(lr_images=False)(\n",
    "                                        Image.fromarray(self.image)\n",
    "                                    )\n",
    "                                )\n",
    "                        else:\n",
    "                            continue\n",
    "            return {\n",
    "                \"train_images\": self.train_images,\n",
    "                \"train_labels\": self.train_labels,\n",
    "                \"test_images\": self.test_images,\n",
    "                \"test_labels\": self.test_labels\n",
    "                }\n",
    "        else:\n",
    "            raise Exception(\"Raw data folder not found\".capitalize())\n",
    "\n",
    "    def create_dataloader(self):\n",
    "        try:\n",
    "            images = self.extract_images()\n",
    "        except Exception as e:\n",
    "            print(\"Error in extracting images\".capitalize())\n",
    "        else:\n",
    "            train_dataloader = DataLoader(\n",
    "                dataset=list(zip(images[\"train_images\"], images[\"train_labels\"])), batch_size=self.batch_size, shuffle=True)\n",
    "            test_dataloader = DataLoader(\n",
    "                dataset=list(zip(images[\"test_images\"], images[\"test_labels\"])), batch_size=self.batch_size*64, shuffle=True)\n",
    "\n",
    "            if os.path.join(PROCESSED_DATA_PATH):\n",
    "                try:\n",
    "                    dump(\n",
    "                        value=train_dataloader, filename=os.path.join(PROCESSED_DATA_PATH, \"train_dataloader.pkl\"))\n",
    "                except Exception as e:\n",
    "                    print(\"Error in dumping train dataloader\".capitalize())\n",
    "\n",
    "                try:   \n",
    "                    dump(\n",
    "                        value=test_dataloader, filename=os.path.join(PROCESSED_DATA_PATH, \"test_dataloader.pkl\"))\n",
    "                except Exception as e:\n",
    "                    print(\"Error in dumping test dataloader\".capitalize())\n",
    "            else:\n",
    "                raise Exception(\"Processed data folder not found\".capitalize())\n",
    "\n",
    "    @staticmethod\n",
    "    def display_images():\n",
    "        if os.path.exists(PROCESSED_DATA_PATH):\n",
    "            images = list()\n",
    "            labels = list()\n",
    "\n",
    "            train_images = load(filename=os.path.join(PROCESSED_DATA_PATH, \"train_dataloader.pkl\"))\n",
    "\n",
    "            for index, (image, label) in enumerate(train_images):\n",
    "\n",
    "                if index !=64:\n",
    "                    images.append(image)\n",
    "                    labels.append(label)\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            plt.figure(figsize=(40, 25))\n",
    "\n",
    "            for index, (lr_image, hr_image) in enumerate(zip(images, labels)):\n",
    "\n",
    "                lr_image = lr_image.squeeze().permute(1, 2, 0)\n",
    "                lr_image = lr_image.cpu().detach().numpy()\n",
    "                lr_image = (lr_image - lr_image.min())/(lr_image.max() - lr_image.min())\n",
    "\n",
    "                plt.subplot(2 * 8, 2 * 8, 2 * index + 1)\n",
    "                plt.imshow(lr_image, cmap=\"gray\")\n",
    "                plt.title(\"lr_image\".lower())\n",
    "                plt.axis(\"off\")\n",
    "\n",
    "                hr_image = hr_image.squeeze().permute(1, 2, 0)\n",
    "                hr_image = hr_image.cpu().detach().numpy()\n",
    "                hr_image = (hr_image - hr_image.min())/(hr_image.max() - hr_image.min())\n",
    "\n",
    "                plt.subplot(2 * 8, 2 * 8, 2 * index + 2)\n",
    "                plt.imshow(hr_image, cmap=\"gray\")\n",
    "                plt.title(\"hr_image\".lower())\n",
    "                plt.axis(\"off\")\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def details_dataset():\n",
    "        if os.path.exists(PROCESSED_DATA_PATH):\n",
    "            train_dataloader = load(filename=os.path.join(PROCESSED_DATA_PATH, \"train_dataloader.pkl\"))\n",
    "            test_dataloader = load(filename=os.path.join(PROCESSED_DATA_PATH, \"test_dataloader.pkl\"))\n",
    "\n",
    "            train = sum(data.size(0) for data, _ in train_dataloader)\n",
    "            test = sum(data.size(0) for data, _ in test_dataloader)\n",
    "\n",
    "            train_lr_images, train_hr_images = next(iter(train_dataloader))\n",
    "            test_lr_images, test_hr_images = next(iter(test_dataloader))\n",
    "\n",
    "            print(\"Train images: {}\".format(train))\n",
    "            print(\"Test images: {}\".format(test))\n",
    "\n",
    "            print(\n",
    "                \"Train: lower resolution images shape: {}\".format(\n",
    "                    train_lr_images.squeeze().size()\n",
    "                ).capitalize()\n",
    "            )\n",
    "            print(\n",
    "                \"Train: higher resolution images shape: {}\".format(\n",
    "                    train_hr_images.squeeze().size()\n",
    "                ).capitalize()\n",
    "            )\n",
    "            print(\n",
    "                \"Test: lower resolution images shape: {}\".format(\n",
    "                    test_lr_images.squeeze().size()\n",
    "                ).capitalize()\n",
    "            )\n",
    "            print(\n",
    "                \"Test: higher resolution images shape: {}\".format(\n",
    "                    test_hr_images.squeeze().size()\n",
    "                ).capitalize()\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"Processed data folder not found\".capitalize())\n",
    "        \n",
    "        \n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    loader = Loader(image_path=\"/Users/shahmuhammadraditrahman/Desktop/images.zip\")\n",
    "    loader.unzip_folder()\n",
    "    loader.create_dataloader()\n",
    "    \n",
    "    loader.details_dataset()\n",
    "    loader.display_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputBlock(nn.Module):\n",
    "    def __init__(self, in_channels = None, out_channels = None):\n",
    "        super(InputBlock, self).__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.kernel_size = 9\n",
    "        self.stride = 1\n",
    "        self.padding = 4\n",
    "        \n",
    "        try:\n",
    "            self.model = self.input_block()\n",
    "        except Exception as e:\n",
    "            print(\"Input block not implemented\")\n",
    "        \n",
    "    def input_block(self):\n",
    "        layers = OrderedDict()\n",
    "        \n",
    "        layers[\"conv\"] = nn.Conv2d(\n",
    "            in_channels = self.in_channels,\n",
    "            out_channels = self.out_channels,\n",
    "            kernel_size = self.kernel_size,\n",
    "            stride = self.stride,\n",
    "            padding = self.padding\n",
    "        )\n",
    "        layers[\"PReLU\"] = nn.PReLU()\n",
    "        \n",
    "        return nn.Sequential(layers)\n",
    "    \n",
    "    def forward(self, x=None):\n",
    "        if x is not None:\n",
    "            return self.model(x)\n",
    "        else:\n",
    "            raise Exception(\"Input block not implemented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels = None, out_channels = None, index = None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.index = index\n",
    "        \n",
    "        self.kernel_size = 3\n",
    "        self.stride = 1\n",
    "        self.padding = 1\n",
    "        \n",
    "        try:\n",
    "            self.model = self.residual_block()\n",
    "        except Exception as e:\n",
    "            print(\"Residual block not implemented\")\n",
    "        \n",
    "    def residual_block(self):\n",
    "        layers = OrderedDict()\n",
    "        \n",
    "        layers[\"conv{}\".format(self.index)] = nn.Conv2d(\n",
    "            in_channels=self.in_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            kernel_size=self.kernel_size,\n",
    "            stride=self.stride,\n",
    "            padding=self.padding\n",
    "        )\n",
    "        layers[\"batchnorm{}\".format(self.index)] = nn.BatchNorm2d(\n",
    "            num_features=self.out_channels)\n",
    "        \n",
    "        layers[\"PReLU{}\".format(self.index)] = nn.PReLU()\n",
    "        layers[\"conv{}\".format(self.index+1)] = nn.Conv2d(\n",
    "            in_channels=self.out_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            kernel_size=self.kernel_size,\n",
    "            stride=self.stride,\n",
    "            padding=self.padding\n",
    "        )\n",
    "        layers[\"batchnorm{}\".format(self.index+1)] = nn.BatchNorm2d(\n",
    "            num_features=self.out_channels)\n",
    "        \n",
    "        return nn.Sequential(layers)\n",
    "    \n",
    "    def forward(self, x=None):\n",
    "        if x is not None:\n",
    "            return x + self.model(x)\n",
    "        else:\n",
    "            raise Exception(\"Residual block not implemented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiddleBlock(nn.Module):\n",
    "    def __init__(self, in_channels = None, out_channels = None):\n",
    "        super(MiddleBlock, self).__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.kernel_size = 3\n",
    "        self.stride = 1\n",
    "        self.padding = 1\n",
    "        \n",
    "        try:\n",
    "            self.model = self.middle_block()\n",
    "        except Exception as _:\n",
    "            print(\"Middle block not implemented\")\n",
    "            \n",
    "    def middle_block(self):\n",
    "        layers = OrderedDict()\n",
    "        \n",
    "        layers[\"conv\"] = nn.Conv2d(\n",
    "            in_channels = self.in_channels,\n",
    "            out_channels = self.out_channels,\n",
    "            kernel_size = self.kernel_size,\n",
    "            stride = self.stride,\n",
    "            padding = self.padding\n",
    "        )\n",
    "        \n",
    "        layers[\"batchnorm\"] = nn.BatchNorm2d(num_features=self.out_channels)\n",
    "        \n",
    "        return nn.Sequential(layers)\n",
    "    \n",
    "    def forward(self, x = None, skip_info = None):\n",
    "        if (x is not None) and (skip_info is not None):\n",
    "            return self.model(x) + skip_info \n",
    "        else:\n",
    "            raise Exception(\"Middle block not implemented\".capitalize())     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpSampleBlock(nn.Module):\n",
    "    def __init__(self, in_channels = None, out_channels = None, is_first_block = False, index = None):\n",
    "        super(UpSampleBlock, self).__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.is_first_block = is_first_block\n",
    "        self.index = index\n",
    "        \n",
    "        self.kernel_size = 3\n",
    "        self.stride = 1\n",
    "        self.padding = 1\n",
    "        self.factor = 2\n",
    "        \n",
    "        try:\n",
    "            self.model = self.up_sample_block()\n",
    "        except Exception as _:\n",
    "            print(\"Up sample block not implemented\".capitalize())\n",
    "            \n",
    "    def up_sample_block(self):\n",
    "        layers = OrderedDict()\n",
    "        layers[\"conv{}\".format(self.index)] = nn.Conv2d(\n",
    "            in_channels=self.in_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            kernel_size=self.kernel_size,\n",
    "            stride=self.stride,\n",
    "            padding=self.padding\n",
    "        )\n",
    "        layers[\"pixel_shuffle{}\".format(self.index)] = nn.PixelShuffle(\n",
    "            upscale_factor=self.factor)\n",
    "        \n",
    "        if self.is_first_block:\n",
    "            layers[\"PReLU\"] = nn.PReLU()\n",
    "            \n",
    "        return nn.Sequential(layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if x is not None:\n",
    "            return self.model(x)\n",
    "        else:\n",
    "            raise Exception(\"Up sample block not implemented\".capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputBlock(nn.Module):\n",
    "    def __init__(self, in_channels = None, out_channels = None):\n",
    "        super(OutputBlock, self).__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.kernel_size = 9\n",
    "        self.stride = 1\n",
    "        self.padding = 4\n",
    "        \n",
    "        try:\n",
    "            self.model = self.output_block()\n",
    "        except Exception as _:\n",
    "            print(\"Output block not implemented\".capitalize())\n",
    "            \n",
    "    def output_block(self):\n",
    "        layers = OrderedDict()\n",
    "        \n",
    "        layers[\"conv\"] = nn.Conv2d(\n",
    "            in_channels = self.in_channels,\n",
    "            out_channels = self.out_channels,\n",
    "            kernel_size = self.kernel_size,\n",
    "            stride=self.stride,\n",
    "            padding = self.padding\n",
    "        )\n",
    "        layers[\"tanh\"] = nn.Tanh()\n",
    "        \n",
    "        return nn.Sequential(layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if x is not None:\n",
    "            return self.model(x)\n",
    "        else:\n",
    "            raise Exception(\"Output block not implemented\".capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.num_repetitive = 16\n",
    "        \n",
    "        self.input_block = InputBlock(in_channels = 3, out_channels = 64)\n",
    "        \n",
    "        self.residual_block = nn.Sequential(\n",
    "            *[ResidualBlock(in_channels=64, out_channels=64, index=index) for index in range(self.num_repetitive)])\n",
    "        \n",
    "        self.middle_block = MiddleBlock(in_channels=64, out_channels=64)\n",
    "        \n",
    "        self.up_sample = nn.Sequential(\n",
    "            *[UpSampleBlock(in_channels=64, out_channels=256, is_first_block=is_first_block, index=index)\n",
    "            for index, is_first_block in enumerate([True, False])])\n",
    "        \n",
    "        self.out_block = OutputBlock(in_channels=64, out_channels=3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if x is not None:\n",
    "            input = self.input_block(x)\n",
    "            residual = self.residual_block(input)\n",
    "            middle = self.middle_block(residual, input)\n",
    "            upsample = self.up_sample(middle)\n",
    "            output = self.out_block(upsample)\n",
    "            \n",
    "            return output\n",
    "        \n",
    "        else:\n",
    "            raise Exception(\"Generator not implemented\".capitalize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputBlock(nn.Module):\n",
    "    def __init__(self, in_channels=None, out_channels=None):\n",
    "        super(InputBlock, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.kernel_size = 3\n",
    "        self.stride = 1\n",
    "        self.padding = 1\n",
    "\n",
    "        self.model = self.input_block()\n",
    "\n",
    "    def input_block(self):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                self.in_channels,\n",
    "                self.out_channels,\n",
    "                self.kernel_size,\n",
    "                self.stride,\n",
    "                self.padding,\n",
    "            ),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.Conv2d(\n",
    "                self.out_channels,\n",
    "                self.out_channels,\n",
    "                self.kernel_size,\n",
    "                self.stride,\n",
    "                self.padding,\n",
    "            ),\n",
    "            nn.BatchNorm2d(num_features=self.out_channels),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x is not None:\n",
    "            return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels=None, out_channels=None, kernel_size=3, stride=2, padding=1\n",
    "    ):\n",
    "        super(FeatureBlock, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "        self.model = self.feature_block()\n",
    "\n",
    "    def feature_block(self):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                self.in_channels,\n",
    "                self.out_channels,\n",
    "                self.kernel_size,\n",
    "                self.stride,\n",
    "                self.padding,\n",
    "            ),\n",
    "            nn.BatchNorm2d(num_features=self.out_channels),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x is not None:\n",
    "            return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutBlock(nn.Module):\n",
    "    def __init__(self, in_channels=None, out_channels=None):\n",
    "        super(OutBlock, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = out_channels\n",
    "\n",
    "        self.model = self.output_block()\n",
    "\n",
    "    def output_block(self):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(self.in_channels * 8, self.in_channels * 16, self.kernel_size),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.Conv2d(self.in_channels * 16, 1, self.kernel_size),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x is not None:\n",
    "            return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=None, out_channels=None):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.filters = out_channels\n",
    "\n",
    "        self.kernel_size = 3\n",
    "        self.stride = 1\n",
    "        self.padding = 1\n",
    "        self.num_repetitive = 7\n",
    "        self.layers = []\n",
    "\n",
    "        self.input = InputBlock(\n",
    "            in_channels=self.in_channels, out_channels=self.out_channels\n",
    "        )\n",
    "\n",
    "        for index in range(self.num_repetitive):\n",
    "            if index % 2:\n",
    "                self.layers.append(\n",
    "                    FeatureBlock(\n",
    "                        in_channels=self.out_channels,\n",
    "                        out_channels=self.out_channels * 2,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                self.out_channels = self.out_channels * 2\n",
    "\n",
    "            else:\n",
    "                self.layers.append(\n",
    "                    FeatureBlock(\n",
    "                        in_channels=self.out_channels, out_channels=self.out_channels\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                self.out_channels = self.out_channels\n",
    "\n",
    "        self.features = nn.Sequential(*self.layers)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveMaxPool2d(output_size=1)\n",
    "\n",
    "        self.output = OutBlock(in_channels=self.filters, out_channels=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        input = self.input(x)\n",
    "        features = self.features(input)\n",
    "        output = self.output(self.avg_pool(features))\n",
    "\n",
    "        return output.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netD = Discriminator(in_channels=3, out_channels=64)\n",
    "\n",
    "netD(torch.randn(1, 3, 256, 256)).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Extractor - VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self, pretrained = True, is_vgg16 = False):\n",
    "        super(VGG16, self).__init__()\n",
    "        \n",
    "        self.pretrained = pretrained\n",
    "        self.is_vgg16 = is_vgg16\n",
    "        self.num_layers = 18\n",
    "        \n",
    "        if self.is_vgg16:\n",
    "            self.model = models.vgg16(pretrained=self.pretrained)\n",
    "            \n",
    "            for params in self.model.parameters():\n",
    "                params.requires_grad = False\n",
    "                \n",
    "        else:\n",
    "            self.model = models.vgg19(pretrained=self.pretrained)\n",
    "            \n",
    "            for params in self.model.parameters():\n",
    "                params.requires_grad = False\n",
    "                \n",
    "        self.model = nn.Sequential(*list(self.model.features.children())[:self.num_layers])\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        if x is not None:\n",
    "            return self.model(x)\n",
    "        else:\n",
    "            raise Exception(\"Feature Extractor not implemented\".capitalize())\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    feature_extractor = VGG16(pretrained=True, is_vgg16=False)\n",
    "    \n",
    "    images = torch.randn(1, 3, 256, 256)\n",
    "    \n",
    "    print(feature_extractor(images).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helpers method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataloader():\n",
    "    if os.path.exists(PROCESSED_DATA_PATH):\n",
    "        train_dataloader = load(\n",
    "            filename=os.path.join(PROCESSED_DATA_PATH, \"train_dataloader.pkl\")\n",
    "        )\n",
    "        test_dataloader = load(\n",
    "            filename=os.path.join(PROCESSED_DATA_PATH, \"test_dataloader.pkl\")\n",
    "        )\n",
    "    else:\n",
    "        raise Exception(\"Dataset not found\".capitalize())\n",
    "\n",
    "    return train_dataloader, test_dataloader\n",
    "\n",
    "\n",
    "def helpers(**kwargs):\n",
    "\n",
    "    lr = kwargs[\"lr\"]\n",
    "    beta1 = kwargs[\"beta1\"]\n",
    "    adam = kwargs[\"adam\"]\n",
    "    SGD = kwargs[\"SGD\"]\n",
    "    device = kwargs[\"device\"]\n",
    "    lr_scheduler = kwargs[\"is_lr_scheduler\"]\n",
    "    netG = netD = optimizerG = optimizerD = schedulerG = schedulerD = None\n",
    "\n",
    "    try:\n",
    "        train_dataloader, test_dataloader = load_dataloader()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"The exception is: \", e)\n",
    "\n",
    "    if adam:\n",
    "        try:\n",
    "            netG = Generator().to(device)\n",
    "            netD = Discriminator(in_channels=3, out_channels=64).to(device)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"The exception caught in the section # {}\".format(e).capitalize())\n",
    "        else:\n",
    "\n",
    "            optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "            optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    elif SGD:\n",
    "        try:\n",
    "            netG = Generator().to(device)\n",
    "            netD = Discriminator(in_channels=3, out_channels=64).to(device)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"The exception caught in the section # {}\".format(e).capitalize())\n",
    "        else:\n",
    "            optimizerG = optim.SGD(netG.parameters(), lr=lr, momentum=beta1)\n",
    "            optimizerD = optim.SGD(netD.parameters(), lr=lr, momentum=beta1)\n",
    "\n",
    "    if lr_scheduler:\n",
    "        schedulerG = StepLR(\n",
    "            optimizerG,\n",
    "            step_size=10,\n",
    "            gamma=0.1,\n",
    "        )\n",
    "        schedulerD = StepLR(\n",
    "            optimizerD,\n",
    "            step_size=10,\n",
    "            gamma=0.1,\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        content_loss = VGG16(pretrained=True).to(device)\n",
    "        adversarial_loss = nn.MSELoss()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"The exception caught in the section # {}\".format(e).capitalize())\n",
    "\n",
    "    return {\n",
    "        \"train_dataloader\": train_dataloader,\n",
    "        \"test_dataloader\": test_dataloader,\n",
    "        \"netG\": netG,\n",
    "        \"netD\": netD,\n",
    "        \"optimizerG\": optimizerG,\n",
    "        \"optimizerD\": optimizerD,\n",
    "        \"schedulerG\": schedulerG,\n",
    "        \"schedulerD\": schedulerD,\n",
    "        \"adversarial_loss\": adversarial_loss,\n",
    "        \"content_loss\": content_loss,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        epochs=100,\n",
    "        lr=0.0002,\n",
    "        content_loss=1e-2,\n",
    "        device=\"mps\",\n",
    "        adam=True,\n",
    "        SGD=False,\n",
    "        beta1=0.5,\n",
    "        is_l1=False,\n",
    "        is_l2=False,\n",
    "        is_elastic_net=False,\n",
    "        is_lr_scheduler=False,\n",
    "        is_weight_init=False,\n",
    "        is_weight_clip=False,\n",
    "        display=True,\n",
    "    ):\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.content_loss = content_loss\n",
    "        self.device = device\n",
    "        self.adam = adam\n",
    "        self.SGD = SGD\n",
    "        self.beta1 = beta1\n",
    "        self.is_l1 = is_l1\n",
    "        self.is_l2 = is_l2\n",
    "        self.is_elastic_net = is_elastic_net\n",
    "        self.is_lr_scheduler = is_lr_scheduler\n",
    "        self.is_weight_init = is_weight_init\n",
    "        self.is_weight_clip = is_weight_clip\n",
    "        self.is_display = display\n",
    "\n",
    "        try:\n",
    "            init = helpers(\n",
    "                lr=self.lr,\n",
    "                beta1=self.beta1,\n",
    "                adam=self.adam,\n",
    "                SGD=self.SGD,\n",
    "                device=self.device,\n",
    "                is_lr_scheduler=self.is_lr_scheduler,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(\"The exception caught in the section # {}\".format(e).capitalize())\n",
    "\n",
    "        else:\n",
    "            self.train_dataloader = init[\"train_dataloader\"]\n",
    "            self.test_dataloader = init[\"test_dataloader\"]\n",
    "\n",
    "            if self.is_weight_init:\n",
    "                self.netG = init[\"netG\"].apply(weight_init)\n",
    "                self.netD = init[\"netD\"].apply(weight_init)\n",
    "\n",
    "            else:\n",
    "                self.netG = init[\"netG\"]\n",
    "                self.netD = init[\"netD\"]\n",
    "\n",
    "            self.optimizerG = init[\"optimizerG\"]\n",
    "            self.optimizerD = init[\"optimizerD\"]\n",
    "            self.schedulerG = init[\"schedulerG\"]\n",
    "            self.schedulerD = init[\"schedulerD\"]\n",
    "            self.adversarial_loss = init[\"adversarial_loss\"]\n",
    "            self.criterion_content = init[\"criterion_loss\"]\n",
    "\n",
    "            self.infinity = float(\"inf\")\n",
    "            self.clip_value = 0.01\n",
    "            self.loss_track = {\"netG\": list(), \"netD\": list()}\n",
    "            self.history = {\"netG\": list(), \"netD\": list()}\n",
    "\n",
    "    def l1(self, model):\n",
    "        if model is not None:\n",
    "            return (\n",
    "                torch.norm(input=params, p=1) for params in model.parameters()\n",
    "            ).sum()\n",
    "        else:\n",
    "            raise Exception(\"Model should be provided\".capitalize())\n",
    "\n",
    "    def l2(self, model):\n",
    "        if model is not None:\n",
    "            return (\n",
    "                torch.norm(input=params, p=2) for params in model.parameters()\n",
    "            ).sum()\n",
    "        else:\n",
    "            raise Exception(\"Model should be provided\".capitalize())\n",
    "\n",
    "    def elastic_net(self, model):\n",
    "        if model is not None:\n",
    "            l1 = self.l1(model=model)\n",
    "            l2 = self.l2(model=model)\n",
    "\n",
    "            return l1 + l2\n",
    "        else:\n",
    "            raise Exception(\"Model should be provided\".capitalize())\n",
    "\n",
    "    def save_checkpoints(self, **kwargs):\n",
    "        if (\n",
    "            (os.path.exists(TRAIN_MODELS))\n",
    "            and (os.path.exists(BEST_MODELS))\n",
    "            and os.path.exists(BEST_MODEL)\n",
    "        ):\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"netG\": self.netG.state_dict(),\n",
    "                    \"netG_loss\": kwargs[\"netG_loss\"],\n",
    "                },\n",
    "                os.path.join(TRAIN_MODELS, \"netG{}.pth\".format(kwargs[\"epoch\"])),\n",
    "            )\n",
    "\n",
    "            self.loss_track[\"netG\"].append(kwargs[\"netG_loss\"])\n",
    "            self.loss_track[\"netD\"].append(kwargs[\"netD_loss\"])\n",
    "\n",
    "            if self.infinity > kwargs[\"netG_loss\"]:\n",
    "\n",
    "                self.infinity = kwargs[\"netG_loss\"]\n",
    "\n",
    "                torch.save(\n",
    "                    {\n",
    "                        \"netG\": self.netG.state_dict(),\n",
    "                        \"netG_loss\": kwargs[\"netG_loss\"],\n",
    "                    },\n",
    "                    os.path.join(BEST_MODELS, \"netG{}.pth\".format(kwargs[\"epoch\"])),\n",
    "                )\n",
    "\n",
    "        else:\n",
    "            raise FileExistsError(\"The directory should be created\".capitalize())\n",
    "\n",
    "    def update_discriminator_training(self, **kwargs):\n",
    "        try:\n",
    "            self.optimizerD.zero_grad()\n",
    "\n",
    "            hr_loss = self.adversarial_loss(\n",
    "                self.netD(kwargs[\"hr_images\"]), kwargs[\"real_labels\"]\n",
    "            )\n",
    "            fake_loss = self.adversarial_loss(\n",
    "                self.netD(self.netG(kwargs[\"lr_images\"])), kwargs[\"fake_labels\"]\n",
    "            )\n",
    "\n",
    "            total_loss = 0.5 * (hr_loss + fake_loss)\n",
    "\n",
    "            if self.is_l2:\n",
    "                total_loss += self.l1(self.netD)\n",
    "\n",
    "            if self.is_elastic_net:\n",
    "                total_loss += self.elastic_net(self.netD)\n",
    "\n",
    "            total_loss.backward()\n",
    "\n",
    "            if self.is_weight_clip:\n",
    "                for params in self.netD.parameters():\n",
    "                    params.data.clamp_(-self.clip_value, self.clip_value)\n",
    "\n",
    "            self.optimizerD.step()\n",
    "\n",
    "        except KeyError as e:\n",
    "            print(\"The exception caught in (Discriminator) # {}\".format(e).capitalize())\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"The exception caught in (Discriminator)# {}\".format(e).capitalize())\n",
    "\n",
    "        else:\n",
    "            return total_loss.item()\n",
    "\n",
    "    def update_generator_training(self, **kwargs):\n",
    "        try:\n",
    "            self.optimizerG.zero_grad()\n",
    "\n",
    "            generated_hr = self.netG(kwargs[\"lr_images\"])\n",
    "\n",
    "            adversarial_loss = self.adversarial_loss(\n",
    "                self.netD(generated_hr), kwargs[\"real_labels\"]\n",
    "            )\n",
    "\n",
    "            real_features = self.criterion_content(kwargs[\"hr_images\"])\n",
    "            fake_features = self.criterion_content(generated_hr)\n",
    "\n",
    "            content_loss_vgg = torch.abs(real_features - fake_features).mean()\n",
    "            total_loss = self.content_loss * adversarial_loss + content_loss_vgg\n",
    "\n",
    "            if self.is_l2:\n",
    "                total_loss += self.l1(self.netG)\n",
    "\n",
    "            if self.is_elastic_net:\n",
    "                total_loss += self.elastic_net(self.netG)\n",
    "\n",
    "            total_loss.backward()\n",
    "            self.optimizerG.step()\n",
    "\n",
    "        except KeyError as e:\n",
    "            print(\"The Exception caught in (Generator) # {}\".format(e).capitalize())\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"The Exception caught in (Generator) # {}\".format(e).capitalize())\n",
    "\n",
    "        else:\n",
    "            return total_loss.item()\n",
    "\n",
    "    def validate_model_on_test_data(self, **kwargs):\n",
    "        try:\n",
    "            generated_hr = self.netG(kwargs[\"lr_images\"])\n",
    "\n",
    "            loss = self.adversarial_loss(generated_hr, kwargs[\"hr_images\"])\n",
    "\n",
    "        except KeyError as e:\n",
    "            print(\"The exception caught in # {}\".format(e).capitalize())\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"The exception caught in # {}\".format(e).capitalize())\n",
    "\n",
    "        else:\n",
    "            return loss.item()\n",
    "\n",
    "    def save_training_images(self, **kwargs):\n",
    "        lr_images, hr_images = next(iter(self.test_dataloader))\n",
    "        lr_images = lr_images.to(self.device)\n",
    "        hr_images = hr_images.to(self.device)\n",
    "\n",
    "        generated_hr_images = self.netG(lr_images[0:8])\n",
    "\n",
    "        if os.path.exists(TRAIN_IMAGES):\n",
    "            save_image(\n",
    "                generated_hr_images,\n",
    "                os.path.join(TRAIN_IMAGES, \"train_{}.png\".format(kwargs[\"epoch\"] + 1)),\n",
    "                nrow=4,\n",
    "                normalize=True,\n",
    "            )\n",
    "        else:\n",
    "            raise FileExistsError(\"The directory should be created\".capitalize())\n",
    "\n",
    "    def show_progress(self, **kwargs):\n",
    "        if self.is_display:\n",
    "            print(\n",
    "                \"Epochs - [{}/{}] - train_netG_loss: {:.5f} - train_netD_loss: {:.5f} - test_loss: {:.5f}\".format(\n",
    "                    kwargs[\"epoch\"],\n",
    "                    kwargs[\"epochs\"],\n",
    "                    np.mean(kwargs[\"netG_loss\"]),\n",
    "                    np.mean(kwargs[\"netD_loss\"]),\n",
    "                    np.mean(kwargs[\"test_loss\"]),\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                \"Epochs - [{}/{}] is completed\".format(\n",
    "                    kwargs[\"epoch\"] + 1, kwargs[\"epochs\"]\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def train(self):\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "        for epoch in tqdm(range(self.epochs)):\n",
    "            self.netG_loss = list()\n",
    "            self.netD_loss = list()\n",
    "            self.test_loss = list()\n",
    "\n",
    "            for _, (lr_images, hr_images) in enumerate(self.train_dataloader):\n",
    "                lr_images = lr_images.to(self.device)\n",
    "                hr_images = hr_images.to(self.device)\n",
    "                batch_size = hr_images.size(0)\n",
    "\n",
    "                real_labels = torch.ones((batch_size,)).to(self.device)\n",
    "                fake_labels = torch.zeros((batch_size,)).to(self.device)\n",
    "\n",
    "                D_loss = self.update_discriminator_training(\n",
    "                    lr_images=lr_images,\n",
    "                    hr_images=hr_images,\n",
    "                    real_labels=real_labels,\n",
    "                    fake_labels=fake_labels,\n",
    "                )\n",
    "                G_loss = self.update_generator_training(\n",
    "                    lr_images=lr_images, hr_images=hr_images, real_labels=real_labels\n",
    "                )\n",
    "\n",
    "                self.netG_loss.append(G_loss)\n",
    "                self.netD_loss.append(D_loss)\n",
    "\n",
    "            for _, (lr_images, hr_images) in enumerate(self.test_dataloader):\n",
    "                lr_images = lr_images.to(self.device)\n",
    "                hr_images = hr_images.to(self.device)\n",
    "\n",
    "                loss = self.validate_model_on_test_data(\n",
    "                    lr_images=lr_images, hr_images=hr_images\n",
    "                )\n",
    "\n",
    "                self.test_loss.append(loss)\n",
    "\n",
    "            try:\n",
    "                self.save_checkpoints(\n",
    "                    epoch=epoch + 1,\n",
    "                    netG_loss=np.array(self.netG_loss).mean(),\n",
    "                    netD_loss=np.array(self.netD_loss).mean(),\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(\"The exception caught in # {}\".format(e).capitalize())\n",
    "\n",
    "            else:\n",
    "                self.save_training_images(epoch=epoch + 1)\n",
    "\n",
    "                self.history[\"netG\"].append(np.mean(self.netG_loss))\n",
    "                self.history[\"netD\"].append(np.mean(self.netD_loss))\n",
    "\n",
    "            finally:\n",
    "                self.show_progress(\n",
    "                    epoch=epoch + 1,\n",
    "                    epochs=self.epochs,\n",
    "                    netG_loss=np.array(self.netG_loss).mean(),\n",
    "                    netD_loss=np.array(self.netD_loss).mean(),\n",
    "                    test_loss=np.array(self.test_loss).mean(),\n",
    "                )\n",
    "\n",
    "            if self.is_lr_scheduler:\n",
    "                self.schedulerD.step()\n",
    "                self.schedulerG.step()\n",
    "        try:\n",
    "            if os.path.exists(MODEL_HISTORY):\n",
    "                pd.DataFrame(self.loss_track).to_csv(\n",
    "                    os.path.join(MODEL_HISTORY, \"history.csv\")\n",
    "                )\n",
    "            else:\n",
    "                raise FileExistsError(\"The directory should be created\".capitalize())\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"The exception caught in # {}\".format(e).capitalize())\n",
    "        else:\n",
    "            if os.path.exists(METRICS_PATH):\n",
    "                dump(\n",
    "                    value=self.history,\n",
    "                    filename=os.path.join(METRICS_PATH, \"history.pkl\"),\n",
    "                )\n",
    "            else:\n",
    "                raise FileExistsError(\n",
    "                    \"The directory should be created (Model History)\".capitalize()\n",
    "                )\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_history():\n",
    "        if os.path.exists(METRICS_PATH):\n",
    "            history = load(filename=os.path.join(METRICS_PATH, \"history.pkl\"))\n",
    "\n",
    "            plt.plot(history[\"netG\"], label=\"netG_loss\")\n",
    "            plt.plot(history[\"netD\"], label=\"netD_loss\")\n",
    "            plt.legend()\n",
    "            plt.xlabel(\"Epochs\".capitalize())\n",
    "            plt.ylabel(\"Loss\".capitalize())\n",
    "            plt.show()\n",
    "\n",
    "        else:\n",
    "            raise FileExistsError(\n",
    "                \"The directory should be created (Model History)\".capitalize()\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    trainer = Trainer(epochs=5, lr=0.0002, device=\"mps\", content_loss=1e-3)\n",
    "    trainer.train()\n",
    "    \n",
    "    trainer.plot_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "class Test:\n",
    "    def __init__(self, device=\"mps\", model=None):\n",
    "        self.device = device_init(device=device)\n",
    "        self.model = model\n",
    "        self.infinity = float(\"inf\")\n",
    "\n",
    "        self.best_model = None\n",
    "        self.netG = Generator().to(self.device)\n",
    "\n",
    "    def load_dataset(self):\n",
    "        if os.path.exists(PROCESSED_DATA_PATH):\n",
    "            return load(\n",
    "                filename=os.path.join(PROCESSED_DATA_PATH, \"test_dataloader.pkl\")\n",
    "            )\n",
    "        else:\n",
    "            raise Exception(\"Dataset not found\".capitalize())\n",
    "\n",
    "    def select_best_model(self):\n",
    "        if os.path.exists(BEST_MODELS):\n",
    "            for model in os.listdir(BEST_MODELS):\n",
    "                if model != \".DS_Store\":\n",
    "                    model_path = os.path.join(BEST_MODELS, model)\n",
    "                    model_loss = torch.load(model_path)\n",
    "                    model_loss = model_loss[\"netG_loss\"]\n",
    "\n",
    "                    if self.infinity > model_loss:\n",
    "                        self.infinity = model_loss\n",
    "\n",
    "                        self.best_model = torch.load(model_path)\n",
    "                        self.best_model = self.best_model[\"netG\"]\n",
    "\n",
    "                return self.best_model\n",
    "        else:\n",
    "            raise Exception(\"Best models not found\".capitalize())\n",
    "\n",
    "    def create_gif(self):\n",
    "        if (os.path.exists(GIF_FILE)) and (os.path.exists(TRAIN_IMAGES)):\n",
    "            self.images = []\n",
    "\n",
    "            for image in os.listdir(TRAIN_IMAGES):\n",
    "                self.images.append(imageio.imread(os.path.join(TRAIN_IMAGES, image)))\n",
    "\n",
    "            imageio.mimsave(os.path.join(GIF_FILE, \"train_gif.gif\"), self.images)\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"GIF file not found\".capitalize())\n",
    "\n",
    "    def image_normalized(self, **kwargs):\n",
    "        return (kwargs[\"image\"] - kwargs[\"image\"].min()) / (\n",
    "            kwargs[\"image\"].max() - kwargs[\"image\"].min()\n",
    "        )\n",
    "\n",
    "    def plot_images(self, **kwargs):\n",
    "        plt.figure(figsize=(80, 40))\n",
    "\n",
    "        lr_images, hr_images = next(iter(self.load_dataset()))\n",
    "        lr_images = lr_images.to(self.device)\n",
    "        hr_images = hr_images.to(self.device)\n",
    "\n",
    "        if self.model:\n",
    "            self.netG.load_state_dict(torch.load(self.model)[\"netG\"])\n",
    "        else:\n",
    "            self.netG.load_state_dict(self.select_best_model())\n",
    "\n",
    "        generated_hr = self.netG(lr_images)\n",
    "\n",
    "        for index, image in enumerate(generated_hr):\n",
    "            lr = lr_images[index].permute(1, 2, 0).squeeze().cpu().detach().numpy()\n",
    "            hr = hr_images[index].permute(1, 2, 0).squeeze().cpu().detach().numpy()\n",
    "            gen_image = image.permute(1, 2, 0).squeeze().cpu().detach().numpy()\n",
    "\n",
    "            lr = self.image_normalized(image=lr)\n",
    "            hr = self.image_normalized(image=hr)\n",
    "            gen_image = self.image_normalized(image=gen_image)\n",
    "\n",
    "            plt.subplot(3 * 8, 3 * 8, 3 * index + 1)\n",
    "            plt.imshow(lr, cmap=\"gray\")\n",
    "            plt.title(\"lr\".lower())\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            plt.subplot(3 * 8, 3 * 8, 3 * index + 2)\n",
    "            plt.imshow(hr, cmap=\"gray\")\n",
    "            plt.title(\"hr\".lower())\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            plt.subplot(3 * 8, 3 * 8, 3 * index + 3)\n",
    "            plt.imshow(gen_image, cmap=\"gray\")\n",
    "            plt.title(\"sr\".upper())\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if os.path.exists(TEST_IMAGES):\n",
    "            plt.savefig(os.path.join(TEST_IMAGES, \"result.png\"))\n",
    "\n",
    "        else:\n",
    "            os.mkdir(TEST_IMAGES)\n",
    "            raise Exception(\n",
    "                \"Could not create the image due to folder is not found\".capitalize()\n",
    "            )\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def plot(self):\n",
    "        try:\n",
    "            self.plot_images(netG=self.netG)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"The exception is: \", e)\n",
    "\n",
    "        else:\n",
    "            self.create_gif()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chart = Test(device=\"mps\")\n",
    "    chart.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPSG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
